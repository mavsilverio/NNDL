{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ac1998e79f0eef",
   "metadata": {},
   "source": [
    "# Assignment 2 – “Image Classification”\n",
    "\n",
    "## Redes Neuronais e Aprendizagem Profunda\n",
    "\n",
    "### Miguel Silvério m55661 | Mestrado em Engenharia Informática\n",
    "### Ricardo Dias 59196 | Mestrado em Inteligência Artificial e Ciência de Dados\n",
    "### Évora 2023/2024\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this project was to create a model capable of estimating the Aerosol Optical Thickness (AOT) at 550 nm for specific locations using Sentinel-2 satellite images. \n",
    "To accomplish this goal, we utilized machine learning techniques to deploy a model capable of analyzing the given images and then predict the closest values. \n",
    "This involved implementing a methodology to preprocess the data and train a model to accurately predict AOT values from the satellite images. \n",
    "Given the complexity and high-dimensional nature of the image data, we analyzed the available modeling architectures and ultimately decided on using a Convolutional Neural Network (CNN).\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset consists of 5 files related to predicting Aerosol Optical Thickness (AOT) at 550 nm using Sentinel-2 imagery:\n",
    "\n",
    "### Train Data\n",
    "- **File:** Train\n",
    "- **Instances:** 10439\n",
    "- **Attributes:** 10 (9 numeric attributes, 1 file)\n",
    "- **Description:** Training dataset for model development.\n",
    "\n",
    "### Test Data\n",
    "- **File:** Test\n",
    "- **Instances:** 2713\n",
    "- **Attributes:** 10 (9 numeric attributes, 1 file)\n",
    "- **Description:** Testing dataset for evaluating model performance.\n",
    "\n",
    "### Sample Submission (Random)\n",
    "- **File:** Sample sub random\n",
    "- **Instances:** 2713\n",
    "- **Attributes:** 2 (2 numeric attributes)\n",
    "- **Description:** Sample submission file format with random values.\n",
    "\n",
    "### Sample Submission (Median)\n",
    "- **File:** Sample sub median\n",
    "- **Instances:** 2713\n",
    "- **Attributes:** 2 (2 numeric attributes)\n",
    "- **Description:** Sample submission file format with median values.\n",
    "\n",
    "### Sample Submission (Mean)\n",
    "- **File:** Sample sub mean\n",
    "- **Instances:** 2713\n",
    "- **Attributes:** 2 (2 numeric attributes)\n",
    "- **Description:** Sample submission file format with median values.\n",
    "\n",
    "## Experimental Set up\n",
    "\n",
    "The first step in our experimental setup involves getting our data ready for analysis. We start by setting up the paths and loading the necessary CSV files to keep everything organized and easily accessible. For loading the images, we use a library called rasterio to read the .tif files. After loading the images, we normalize the data pixel value to 0 and 1 values. This step is crucial because it standardizes the inputs making the training process smoother and more efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da69be48-254e-4043-a4d9-38a455a740b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Limitar GPU MEmory Consumption\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ffbec1e-0e1a-4b76-835d-c156b3c88bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n",
      "13 channels\n"
     ]
    }
   ],
   "source": [
    "#Find number of channels per image\n",
    "import os\n",
    "import rasterio\n",
    "\n",
    "# Path to the TIFF file\n",
    "tif_path = 'test/AgiaMarina_Xyliatou_35-038_33-0577_COPERNICUS_S2_20190114T083311_20190114T083309_T36SVD.tif'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(tif_path):\n",
    "    print(\"File exists\")\n",
    "    \n",
    "    # Open the TIFF file\n",
    "    with rasterio.open(tif_path) as imagens:\n",
    "        # Number of channels\n",
    "        num_channels = imagens.count\n",
    "\n",
    "    print(f\"{num_channels} channels\")\n",
    "else:\n",
    "    print(\"File does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589d4acc-ea60-48fd-ac7b-3fdd60e8ca1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images...\n",
      "100 train images loaded\n",
      "200 train images loaded\n",
      "300 train images loaded\n",
      "400 train images loaded\n",
      "500 train images loaded\n",
      "600 train images loaded\n",
      "700 train images loaded\n",
      "800 train images loaded\n",
      "900 train images loaded\n",
      "1000 train images loaded\n",
      "1100 train images loaded\n",
      "1200 train images loaded\n",
      "1300 train images loaded\n",
      "1400 train images loaded\n",
      "1500 train images loaded\n",
      "1600 train images loaded\n",
      "1700 train images loaded\n",
      "1800 train images loaded\n",
      "1900 train images loaded\n",
      "2000 train images loaded\n",
      "2100 train images loaded\n",
      "2200 train images loaded\n",
      "2300 train images loaded\n",
      "2400 train images loaded\n",
      "2500 train images loaded\n",
      "2600 train images loaded\n",
      "2700 train images loaded\n",
      "2800 train images loaded\n",
      "2900 train images loaded\n",
      "3000 train images loaded\n",
      "3100 train images loaded\n",
      "3200 train images loaded\n",
      "3300 train images loaded\n",
      "3400 train images loaded\n",
      "3500 train images loaded\n",
      "3600 train images loaded\n",
      "3700 train images loaded\n",
      "3800 train images loaded\n",
      "3900 train images loaded\n",
      "4000 train images loaded\n",
      "4100 train images loaded\n",
      "4200 train images loaded\n",
      "4300 train images loaded\n",
      "4400 train images loaded\n",
      "4500 train images loaded\n",
      "4600 train images loaded\n",
      "4700 train images loaded\n",
      "4800 train images loaded\n",
      "4900 train images loaded\n",
      "5000 train images loaded\n",
      "5100 train images loaded\n",
      "5200 train images loaded\n",
      "5300 train images loaded\n",
      "5400 train images loaded\n",
      "5500 train images loaded\n",
      "5600 train images loaded\n",
      "5700 train images loaded\n",
      "5800 train images loaded\n",
      "5900 train images loaded\n",
      "6000 train images loaded\n",
      "6100 train images loaded\n",
      "6200 train images loaded\n",
      "6300 train images loaded\n",
      "6400 train images loaded\n",
      "6500 train images loaded\n",
      "6600 train images loaded\n",
      "6700 train images loaded\n",
      "6800 train images loaded\n",
      "6900 train images loaded\n",
      "7000 train images loaded\n",
      "7100 train images loaded\n",
      "7200 train images loaded\n",
      "7300 train images loaded\n",
      "7400 train images loaded\n",
      "7500 train images loaded\n",
      "7600 train images loaded\n",
      "7700 train images loaded\n",
      "7800 train images loaded\n",
      "7900 train images loaded\n",
      "8000 train images loaded\n",
      "8100 train images loaded\n",
      "8200 train images loaded\n",
      "8300 train images loaded\n",
      "8400 train images loaded\n",
      "8500 train images loaded\n",
      "8600 train images loaded\n",
      "8700 train images loaded\n",
      "8800 train images loaded\n",
      "8900 train images loaded\n",
      "9000 train images loaded\n",
      "9100 train images loaded\n",
      "9200 train images loaded\n",
      "9300 train images loaded\n",
      "9400 train images loaded\n",
      "9500 train images loaded\n",
      "9600 train images loaded\n",
      "9700 train images loaded\n",
      "9800 train images loaded\n",
      "9900 train images loaded\n",
      "10000 train images loaded\n",
      "10100 train images loaded\n",
      "10200 train images loaded\n",
      "10300 train images loaded\n",
      "10400 train images loaded\n",
      "Loading test images...\n",
      "100 test images loaded\n",
      "200 test images loaded\n",
      "300 test images loaded\n",
      "400 test images loaded\n",
      "500 test images loaded\n",
      "600 test images loaded\n",
      "700 test images loaded\n",
      "800 test images loaded\n",
      "900 test images loaded\n",
      "1000 test images loaded\n",
      "1100 test images loaded\n",
      "1200 test images loaded\n",
      "1300 test images loaded\n",
      "1400 test images loaded\n",
      "1500 test images loaded\n",
      "1600 test images loaded\n",
      "1700 test images loaded\n",
      "1800 test images loaded\n",
      "1900 test images loaded\n",
      "2000 test images loaded\n",
      "2100 test images loaded\n",
      "2200 test images loaded\n",
      "2300 test images loaded\n",
      "2400 test images loaded\n",
      "2500 test images loaded\n",
      "2600 test images loaded\n",
      "2700 test images loaded\n",
      "x_train_images (10438, 19, 19, 13)\n",
      "y_train (10438,)\n",
      "x_test_images (2712, 19, 19, 13)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import rasterio\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "# Directories containing images\n",
    "train_image_dir = 'train'\n",
    "test_image_dir = 'test'\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Initialize lists to store training images and labels\n",
    "x_train_images = []\n",
    "y_train = []\n",
    "\n",
    "print(\"Loading training images...\")\n",
    "\n",
    "# Loop through each row in the training DataFrame\n",
    "for index, row in train_df.iterrows():\n",
    "    nomeimg = row['file_name_l1']\n",
    "    aot = row['value_550']\n",
    "    if nomeimg.endswith('.tif'):  # Check if the file is a .tif image\n",
    "        pathimagem = os.path.join(train_image_dir, nomeimg)  # Get the full path to the image\n",
    "        y_train.append(aot)  # Append the AOT_550 value to the labels list\n",
    "\n",
    "        # Load image\n",
    "        with rasterio.open(pathimagem) as imagens:\n",
    "            imagem = imagens.read(list(range(1, 14)))  # Reading all 13 bands\n",
    "            imagem = np.moveaxis(imagem, 0, -1)  # Move the channel axis to the last position\n",
    "            x_train_images.append(img_to_array(imagem))  # Convert the image to an array and append to the list\n",
    "\n",
    "        # Print progress every 100 images\n",
    "        if (index + 1) % 100 == 0:\n",
    "            print(f\"{index + 1} train images loaded\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_train_images = np.array(x_train_images)  # Convert list of training images to numpy array\n",
    "y_train = np.array(y_train)  # Convert list of labels to numpy array\n",
    "\n",
    "# Normalize the image data\n",
    "x_train_images = x_train_images / 255.0  # Normalize pixel values to the range [0, 1] to improve NN performance\n",
    "\n",
    "print(\"Loading test images...\")\n",
    "\n",
    "# Initialize lists to store test images\n",
    "x_test_images = []\n",
    "\n",
    "# Loop through each row in the test DataFrame\n",
    "for index, row in test_df.iterrows():\n",
    "    nomeimg = row['file_name_l1']\n",
    "    if nomeimg.endswith('.tif'):  # Check if the file is a .tif image\n",
    "        pathimagem = os.path.join(test_image_dir, nomeimg)  # Get the full path to the image\n",
    "\n",
    "        # Load image using Rasterio\n",
    "        with rasterio.open(pathimagem) as imagens:\n",
    "            imagem = imagens.read(list(range(1, 14)))  # Reading all 13 bands\n",
    "            imagem = np.moveaxis(imagem, 0, -1)  # Move the channel axis to the last position\n",
    "            x_test_images.append(img_to_array(imagem))  # Convert the image to an array and append to the list\n",
    "\n",
    "        # Print progress every 100 images\n",
    "        if (index + 1) % 100 == 0:\n",
    "            print(f\"{index + 1} test images loaded\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_test_images = np.array(x_test_images)  # Convert list of test images to numpy array\n",
    "\n",
    "# Normalize the image data\n",
    "x_test_images = x_test_images / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "# Print shapes to verify the data loading process\n",
    "print(\"x_train_images\", x_train_images.shape)  # Print training images array\n",
    "print(\"y_train\", y_train.shape)  # Print labels array\n",
    "print(\"x_test_images\", x_test_images.shape)  # Print test images array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e55e0fc2ceb11",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "In the next phase of our experimental setup, we focus on designing the model architecture. For the convolutional layers, we use Conv2D with ReLU activation to extract spatial features from the Sentinel-2 images. \n",
    "We sequentially apply layers with 64, 128, and 256 filters to capture a variety of patterns in the data. \n",
    "Batch normalization is included to stabilize training and aid in convergence. To manage the spatial dimensions of the feature maps, we use MaxPooling2D layers which help retain important spatial information while reducing the computational load. Dropout layers are also implemented to prevent overfitting by randomly disabling a fraction of input units during training which promotes better generalization. \n",
    "Next, we configured these layers with 512, 256, and 128 units to capture complex relationships within the data. \n",
    "For the output layer, we use a single neuron with linear activation to predict the continuous AOT value. \n",
    "To optimize the model, we employ the Adam optimizer known for its adaptive learning rate mechanism which is highly effective for training deep neural networks efficiently. \n",
    "Our chosen loss function is Mean Absolute Error (MAE) which directly measures the average magnitude of errors in the prediction of AOT values providing a clear metric for model performance.\n",
    "\n",
    "### Convolutional Layers:\n",
    "- We use Conv2D with ReLU activation to extract spatial features from Sentinel-2 images. \n",
    "- The layers employ 64, 128, and 256 filters sequentially to capture different patterns.\n",
    "\n",
    "### Batch Normalization: \n",
    "- Included to stabilize training aiding in convergence.\n",
    "\n",
    "### Pooling Layers: \n",
    "- MaxPooling2D reduces the spatial dimensions of feature maps helping to maintain important spatial information while reducing computational load.\n",
    "\n",
    "### Dropout: \n",
    "- Implemented to prevent overfitting by randomly disabling a fraction of input units during training promoting generalization.\n",
    "\n",
    "### Dense Layers: \n",
    "- These fully connected layers interpret the extracted features. We've chosen configurations with 512, 256, and 128 units to capture complex relationships in the data.\n",
    "\n",
    "### Output Layer: \n",
    "- A single neuron with linear activation is used to predict the continuous AOT value.\n",
    "\n",
    "### Optimizer: \n",
    "- We employ the Adam optimizer due to its adaptive learning rate mechanism which is beneficial for training deep neural networks efficiently.\n",
    "\n",
    "### Loss Function: \n",
    "- Mean Absolute Error (MAE) serves as our loss function directly measuring the average magnitude of errors in the prediction of AOT values.\n",
    "\n",
    "## Model Training\n",
    "\n",
    "In this phase of our experimental setup, we focus on training the model. We start with a train-validation split. Using an 80-20 split, we ensure that a substantial portion of the data is dedicated to training while keeping enough data aside to validate the model's performance on unseen samples. To maintain consistency and reproducibility, we set a random state for this split. When training the model, we experimented with two different configurations: training for 30 epochs with a batch size of 300 and training for 100 epochs with a batch size of 100. The use of validation data during training is crucial as it helps us monitor the model's performance on unseen data, providing early insights into potential overfitting issues.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "After training, we evaluated the model. We start by plotting the training history, displaying the MAE for the validation subset vs the MAE of the training subset over epochs. By visualizing both training and validation MAE, we can see how the model learns over time, identify trends, and spot any potential overfitting or underfitting issues.\n",
    "\n",
    "## Predictions and Submission\n",
    "\n",
    "Finally, we evaluate the model on the test subset to get a final check on its performance. This step ensures that the model generalizes well to new and unseen data and makes correct predictions. These predictions are then formatted according to the submission requirements and submitted for evaluation.\n",
    "\n",
    "## Decision-Making Process for Model Selection and Parameters Specification\n",
    "\n",
    "We chose a Convolutional Neural Network (CNN) for this task because satellite images are high-dimensional data with a spatial structure, which CNNs are specifically designed to handle. CNNs can automatically learn spatial hierarchies of features, essential for capturing complex patterns in multi-band satellite data, which is the case with the given dataset.\n",
    "\n",
    "## Parameters Specification\n",
    "\n",
    "### Model Architecture:\n",
    "- Convolutional layers with 64, 128, and 256 filters allow the model to capture increasingly complex patterns efficiently.\n",
    "- A kernel size of 3x3 is chosen for its balance in capturing fine details and relevant patterns.\n",
    "- Using 'same' padding preserves image size.\n",
    "\n",
    "### Regularization Techniques:\n",
    "- Batch normalization stabilizes and accelerates training by normalizing the outputs of previous layers.\n",
    "- Dropout layers (with a 0.3 dropout rate) prevent overfitting by randomly dropping a fraction of the neurons during training.\n",
    "\n",
    "### Activation Function:\n",
    "- ReLU is used for its ability to mitigate the vanishing gradient problem where the gradients become too small and stop the weights from being updated.\n",
    "\n",
    "### Optimizer:\n",
    "- The Adam optimizer was selected for its adaptive learning rate capabilities, making it effective for training deep networks with sparse gradients and noisy data.\n",
    "\n",
    "### Loss Function:\n",
    "- Mean Absolute Error (MAE) was chosen for this regression task as it directly measures the average size of errors in predictions.\n",
    "\n",
    "### Training Settings:\n",
    "- 300 and 100 were the chosen test epochs to ensure the model has enough time to learn from the data without overfitting.\n",
    "- A batch size of 30 and 100 were put to test to balance memory usage, convergence speed, and obtain more stable MAE predictions due to the training history plot.\n",
    "\n",
    "These decisions were made to ensure the model effectively captures the complexity of the satellite image data while maintaining efficient training and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80355d7e-82f3-4ec5-baa0-57eeb506638b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 19, 19, 64)        7552      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 19, 19, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 9, 9, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 9, 9, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,067,521\n",
      "Trainable params: 1,066,625\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.2528 - mae: 0.2528Epoch 1 completed. Loss: 0.2528, MAE: 0.2528, Val Loss: 0.0889, Val MAE: 0.0889\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.2528 - mae: 0.2528 - val_loss: 0.0889 - val_mae: 0.0889\n",
      "Epoch 2/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0916 - mae: 0.0916Epoch 2 completed. Loss: 0.0913, MAE: 0.0913, Val Loss: 0.0877, Val MAE: 0.0877\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.0877 - val_mae: 0.0877\n",
      "Epoch 3/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0856 - mae: 0.0856Epoch 3 completed. Loss: 0.0858, MAE: 0.0858, Val Loss: 0.0957, Val MAE: 0.0957\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0858 - mae: 0.0858 - val_loss: 0.0957 - val_mae: 0.0957\n",
      "Epoch 4/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0817 - mae: 0.0817Epoch 4 completed. Loss: 0.0816, MAE: 0.0816, Val Loss: 0.1282, Val MAE: 0.1282\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0816 - mae: 0.0816 - val_loss: 0.1282 - val_mae: 0.1282\n",
      "Epoch 5/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0807 - mae: 0.0807Epoch 5 completed. Loss: 0.0807, MAE: 0.0807, Val Loss: 0.0996, Val MAE: 0.0996\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0807 - mae: 0.0807 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 6/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0794 - mae: 0.0794Epoch 6 completed. Loss: 0.0793, MAE: 0.0793, Val Loss: 0.0923, Val MAE: 0.0923\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0793 - mae: 0.0793 - val_loss: 0.0923 - val_mae: 0.0923\n",
      "Epoch 7/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0788 - mae: 0.0788Epoch 7 completed. Loss: 0.0787, MAE: 0.0787, Val Loss: 0.0768, Val MAE: 0.0768\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0787 - mae: 0.0787 - val_loss: 0.0768 - val_mae: 0.0768\n",
      "Epoch 8/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0777 - mae: 0.0777Epoch 8 completed. Loss: 0.0777, MAE: 0.0777, Val Loss: 0.0802, Val MAE: 0.0802\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0777 - mae: 0.0777 - val_loss: 0.0802 - val_mae: 0.0802\n",
      "Epoch 9/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0774 - mae: 0.0774Epoch 9 completed. Loss: 0.0774, MAE: 0.0774, Val Loss: 0.1444, Val MAE: 0.1444\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0774 - mae: 0.0774 - val_loss: 0.1444 - val_mae: 0.1444\n",
      "Epoch 10/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0781 - mae: 0.0781Epoch 10 completed. Loss: 0.0781, MAE: 0.0781, Val Loss: 0.0837, Val MAE: 0.0837\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0781 - mae: 0.0781 - val_loss: 0.0837 - val_mae: 0.0837\n",
      "Epoch 11/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0778 - mae: 0.0778Epoch 11 completed. Loss: 0.0778, MAE: 0.0778, Val Loss: 0.0833, Val MAE: 0.0833\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0778 - mae: 0.0778 - val_loss: 0.0833 - val_mae: 0.0833\n",
      "Epoch 12/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0783 - mae: 0.0783Epoch 12 completed. Loss: 0.0783, MAE: 0.0783, Val Loss: 0.0854, Val MAE: 0.0854\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0783 - mae: 0.0783 - val_loss: 0.0854 - val_mae: 0.0854\n",
      "Epoch 13/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0784 - mae: 0.0784Epoch 13 completed. Loss: 0.0784, MAE: 0.0784, Val Loss: 0.0871, Val MAE: 0.0871\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0784 - mae: 0.0784 - val_loss: 0.0871 - val_mae: 0.0871\n",
      "Epoch 14/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0778 - mae: 0.0778Epoch 14 completed. Loss: 0.0776, MAE: 0.0776, Val Loss: 0.0828, Val MAE: 0.0828\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0776 - mae: 0.0776 - val_loss: 0.0828 - val_mae: 0.0828\n",
      "Epoch 15/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0769 - mae: 0.0769Epoch 15 completed. Loss: 0.0769, MAE: 0.0769, Val Loss: 0.0822, Val MAE: 0.0822\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0769 - mae: 0.0769 - val_loss: 0.0822 - val_mae: 0.0822\n",
      "Epoch 16/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0771 - mae: 0.0771Epoch 16 completed. Loss: 0.0771, MAE: 0.0771, Val Loss: 0.0747, Val MAE: 0.0747\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0747 - val_mae: 0.0747\n",
      "Epoch 17/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0768 - mae: 0.0768Epoch 17 completed. Loss: 0.0764, MAE: 0.0764, Val Loss: 0.0747, Val MAE: 0.0747\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0764 - mae: 0.0764 - val_loss: 0.0747 - val_mae: 0.0747\n",
      "Epoch 18/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0767 - mae: 0.0767Epoch 18 completed. Loss: 0.0764, MAE: 0.0764, Val Loss: 0.0803, Val MAE: 0.0803\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0764 - mae: 0.0764 - val_loss: 0.0803 - val_mae: 0.0803\n",
      "Epoch 19/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0757 - mae: 0.0757Epoch 19 completed. Loss: 0.0757, MAE: 0.0757, Val Loss: 0.0813, Val MAE: 0.0813\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0757 - mae: 0.0757 - val_loss: 0.0813 - val_mae: 0.0813\n",
      "Epoch 20/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0755 - mae: 0.0755Epoch 20 completed. Loss: 0.0754, MAE: 0.0754, Val Loss: 0.0786, Val MAE: 0.0786\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0754 - mae: 0.0754 - val_loss: 0.0786 - val_mae: 0.0786\n",
      "Epoch 21/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0760 - mae: 0.0760Epoch 21 completed. Loss: 0.0760, MAE: 0.0760, Val Loss: 0.0763, Val MAE: 0.0763\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0760 - mae: 0.0760 - val_loss: 0.0763 - val_mae: 0.0763\n",
      "Epoch 22/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0754 - mae: 0.0754Epoch 22 completed. Loss: 0.0754, MAE: 0.0754, Val Loss: 0.0737, Val MAE: 0.0737\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0754 - mae: 0.0754 - val_loss: 0.0737 - val_mae: 0.0737\n",
      "Epoch 23/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0740 - mae: 0.0740Epoch 23 completed. Loss: 0.0743, MAE: 0.0743, Val Loss: 0.0776, Val MAE: 0.0776\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0776 - val_mae: 0.0776\n",
      "Epoch 24/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0734 - mae: 0.0734Epoch 24 completed. Loss: 0.0732, MAE: 0.0732, Val Loss: 0.0828, Val MAE: 0.0828\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0732 - mae: 0.0732 - val_loss: 0.0828 - val_mae: 0.0828\n",
      "Epoch 25/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0751 - mae: 0.0751Epoch 25 completed. Loss: 0.0752, MAE: 0.0752, Val Loss: 0.0754, Val MAE: 0.0754\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0752 - mae: 0.0752 - val_loss: 0.0754 - val_mae: 0.0754\n",
      "Epoch 26/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0743 - mae: 0.0743Epoch 26 completed. Loss: 0.0746, MAE: 0.0746, Val Loss: 0.1309, Val MAE: 0.1309\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0746 - mae: 0.0746 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 27/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0732 - mae: 0.0732Epoch 27 completed. Loss: 0.0730, MAE: 0.0730, Val Loss: 0.0894, Val MAE: 0.0894\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0730 - mae: 0.0730 - val_loss: 0.0894 - val_mae: 0.0894\n",
      "Epoch 28/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0753 - mae: 0.0753Epoch 28 completed. Loss: 0.0754, MAE: 0.0754, Val Loss: 0.1841, Val MAE: 0.1841\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0754 - mae: 0.0754 - val_loss: 0.1841 - val_mae: 0.1841\n",
      "Epoch 29/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0752 - mae: 0.0752Epoch 29 completed. Loss: 0.0754, MAE: 0.0754, Val Loss: 0.0696, Val MAE: 0.0696\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0754 - mae: 0.0754 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 30/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0734 - mae: 0.0734Epoch 30 completed. Loss: 0.0734, MAE: 0.0734, Val Loss: 0.0680, Val MAE: 0.0680\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0734 - mae: 0.0734 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 31/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0743 - mae: 0.0743Epoch 31 completed. Loss: 0.0743, MAE: 0.0743, Val Loss: 0.0715, Val MAE: 0.0715\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 32/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0742 - mae: 0.0742Epoch 32 completed. Loss: 0.0741, MAE: 0.0741, Val Loss: 0.0729, Val MAE: 0.0729\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 33/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0734 - mae: 0.0734Epoch 33 completed. Loss: 0.0733, MAE: 0.0733, Val Loss: 0.0836, Val MAE: 0.0836\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0733 - mae: 0.0733 - val_loss: 0.0836 - val_mae: 0.0836\n",
      "Epoch 34/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0736 - mae: 0.0736Epoch 34 completed. Loss: 0.0738, MAE: 0.0738, Val Loss: 0.0959, Val MAE: 0.0959\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0738 - mae: 0.0738 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 35/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0742 - mae: 0.0742Epoch 35 completed. Loss: 0.0741, MAE: 0.0741, Val Loss: 0.0814, Val MAE: 0.0814\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0814 - val_mae: 0.0814\n",
      "Epoch 36/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0729 - mae: 0.0729Epoch 36 completed. Loss: 0.0729, MAE: 0.0729, Val Loss: 0.0712, Val MAE: 0.0712\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0729 - mae: 0.0729 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 37/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0720 - mae: 0.0720Epoch 37 completed. Loss: 0.0721, MAE: 0.0721, Val Loss: 0.0657, Val MAE: 0.0657\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0721 - mae: 0.0721 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 38/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0720 - mae: 0.0720Epoch 38 completed. Loss: 0.0719, MAE: 0.0719, Val Loss: 0.0690, Val MAE: 0.0690\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0719 - mae: 0.0719 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 39/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0717 - mae: 0.0717Epoch 39 completed. Loss: 0.0716, MAE: 0.0716, Val Loss: 0.6062, Val MAE: 0.6062\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.6062 - val_mae: 0.6062\n",
      "Epoch 40/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0724 - mae: 0.0724Epoch 40 completed. Loss: 0.0724, MAE: 0.0724, Val Loss: 0.1092, Val MAE: 0.1092\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0724 - mae: 0.0724 - val_loss: 0.1092 - val_mae: 0.1092\n",
      "Epoch 41/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0720 - mae: 0.0720Epoch 41 completed. Loss: 0.0721, MAE: 0.0721, Val Loss: 0.0783, Val MAE: 0.0783\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0721 - mae: 0.0721 - val_loss: 0.0783 - val_mae: 0.0783\n",
      "Epoch 42/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0712 - mae: 0.0712Epoch 42 completed. Loss: 0.0710, MAE: 0.0710, Val Loss: 0.0662, Val MAE: 0.0662\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0710 - mae: 0.0710 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 43/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0705 - mae: 0.0705Epoch 43 completed. Loss: 0.0705, MAE: 0.0705, Val Loss: 0.0712, Val MAE: 0.0712\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 44/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0701 - mae: 0.0701Epoch 44 completed. Loss: 0.0702, MAE: 0.0702, Val Loss: 0.1182, Val MAE: 0.1182\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 45/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0699 - mae: 0.0699Epoch 45 completed. Loss: 0.0700, MAE: 0.0700, Val Loss: 0.0719, Val MAE: 0.0719\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 46/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0699 - mae: 0.0699Epoch 46 completed. Loss: 0.0701, MAE: 0.0701, Val Loss: 0.0669, Val MAE: 0.0669\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 47/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0695 - mae: 0.0695Epoch 47 completed. Loss: 0.0697, MAE: 0.0697, Val Loss: 0.0762, Val MAE: 0.0762\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0762 - val_mae: 0.0762\n",
      "Epoch 48/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0696 - mae: 0.0696Epoch 48 completed. Loss: 0.0696, MAE: 0.0696, Val Loss: 0.0779, Val MAE: 0.0779\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0779 - val_mae: 0.0779\n",
      "Epoch 49/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0691 - mae: 0.0691Epoch 49 completed. Loss: 0.0689, MAE: 0.0689, Val Loss: 0.0656, Val MAE: 0.0656\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0689 - mae: 0.0689 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 50/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0708 - mae: 0.0708Epoch 50 completed. Loss: 0.0707, MAE: 0.0707, Val Loss: 0.0690, Val MAE: 0.0690\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0707 - mae: 0.0707 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 51/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0703 - mae: 0.0703Epoch 51 completed. Loss: 0.0702, MAE: 0.0702, Val Loss: 0.0775, Val MAE: 0.0775\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0775 - val_mae: 0.0775\n",
      "Epoch 52/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0698 - mae: 0.0698Epoch 52 completed. Loss: 0.0696, MAE: 0.0696, Val Loss: 0.0661, Val MAE: 0.0661\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 53/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0703 - mae: 0.0703Epoch 53 completed. Loss: 0.0702, MAE: 0.0702, Val Loss: 0.1321, Val MAE: 0.1321\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.1321 - val_mae: 0.1321\n",
      "Epoch 54/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0698 - mae: 0.0698Epoch 54 completed. Loss: 0.0698, MAE: 0.0698, Val Loss: 0.0690, Val MAE: 0.0690\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 55/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0704 - mae: 0.0704Epoch 55 completed. Loss: 0.0704, MAE: 0.0704, Val Loss: 0.0722, Val MAE: 0.0722\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 56/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0690 - mae: 0.0690Epoch 56 completed. Loss: 0.0690, MAE: 0.0690, Val Loss: 0.0798, Val MAE: 0.0798\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0798 - val_mae: 0.0798\n",
      "Epoch 57/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0691 - mae: 0.0691Epoch 57 completed. Loss: 0.0691, MAE: 0.0691, Val Loss: 0.0765, Val MAE: 0.0765\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0691 - mae: 0.0691 - val_loss: 0.0765 - val_mae: 0.0765\n",
      "Epoch 58/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0690 - mae: 0.0690Epoch 58 completed. Loss: 0.0690, MAE: 0.0690, Val Loss: 0.0652, Val MAE: 0.0652\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 59/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0685 - mae: 0.0685Epoch 59 completed. Loss: 0.0684, MAE: 0.0684, Val Loss: 0.0695, Val MAE: 0.0695\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 60/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0677 - mae: 0.0677Epoch 60 completed. Loss: 0.0677, MAE: 0.0677, Val Loss: 0.0643, Val MAE: 0.0643\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 61/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0677 - mae: 0.0677Epoch 61 completed. Loss: 0.0675, MAE: 0.0675, Val Loss: 0.1355, Val MAE: 0.1355\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.1355 - val_mae: 0.1355\n",
      "Epoch 62/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0673 - mae: 0.0673Epoch 62 completed. Loss: 0.0673, MAE: 0.0673, Val Loss: 0.0718, Val MAE: 0.0718\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 63/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0680 - mae: 0.0680Epoch 63 completed. Loss: 0.0679, MAE: 0.0679, Val Loss: 0.0707, Val MAE: 0.0707\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 64/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0661 - mae: 0.0661Epoch 64 completed. Loss: 0.0664, MAE: 0.0664, Val Loss: 0.0722, Val MAE: 0.0722\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 65/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0672 - mae: 0.0672Epoch 65 completed. Loss: 0.0672, MAE: 0.0672, Val Loss: 0.0648, Val MAE: 0.0648\n",
      "279/279 [==============================] - 2s 5ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 66/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0675 - mae: 0.0675Epoch 66 completed. Loss: 0.0674, MAE: 0.0674, Val Loss: 0.0849, Val MAE: 0.0849\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0849 - val_mae: 0.0849\n",
      "Epoch 67/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0660 - mae: 0.0660Epoch 67 completed. Loss: 0.0664, MAE: 0.0664, Val Loss: 0.1848, Val MAE: 0.1848\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.1848 - val_mae: 0.1848\n",
      "Epoch 68/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0671 - mae: 0.0671Epoch 68 completed. Loss: 0.0670, MAE: 0.0670, Val Loss: 0.0852, Val MAE: 0.0852\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0852 - val_mae: 0.0852\n",
      "Epoch 69/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0680 - mae: 0.0680Epoch 69 completed. Loss: 0.0679, MAE: 0.0679, Val Loss: 0.0717, Val MAE: 0.0717\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0717 - val_mae: 0.0717\n",
      "Epoch 70/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0674 - mae: 0.0674Epoch 70 completed. Loss: 0.0671, MAE: 0.0671, Val Loss: 0.0926, Val MAE: 0.0926\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0926 - val_mae: 0.0926\n",
      "Epoch 71/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0671 - mae: 0.0671Epoch 71 completed. Loss: 0.0669, MAE: 0.0669, Val Loss: 0.0711, Val MAE: 0.0711\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0711 - val_mae: 0.0711\n",
      "Epoch 72/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0661 - mae: 0.0661Epoch 72 completed. Loss: 0.0663, MAE: 0.0663, Val Loss: 0.0767, Val MAE: 0.0767\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0767 - val_mae: 0.0767\n",
      "Epoch 73/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0666 - mae: 0.0666Epoch 73 completed. Loss: 0.0666, MAE: 0.0666, Val Loss: 0.1410, Val MAE: 0.1410\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 74/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0661 - mae: 0.0661Epoch 74 completed. Loss: 0.0661, MAE: 0.0661, Val Loss: 0.1408, Val MAE: 0.1408\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.1408 - val_mae: 0.1408\n",
      "Epoch 75/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0669 - mae: 0.0669Epoch 75 completed. Loss: 0.0666, MAE: 0.0666, Val Loss: 0.0693, Val MAE: 0.0693\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 76/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0662 - mae: 0.0662Epoch 76 completed. Loss: 0.0662, MAE: 0.0662, Val Loss: 0.0682, Val MAE: 0.0682\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 77/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0665 - mae: 0.0665Epoch 77 completed. Loss: 0.0666, MAE: 0.0666, Val Loss: 0.0652, Val MAE: 0.0652\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 78/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0660 - mae: 0.0660Epoch 78 completed. Loss: 0.0659, MAE: 0.0659, Val Loss: 0.0639, Val MAE: 0.0639\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 79/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0660 - mae: 0.0660Epoch 79 completed. Loss: 0.0660, MAE: 0.0660, Val Loss: 0.0740, Val MAE: 0.0740\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0740 - val_mae: 0.0740\n",
      "Epoch 80/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0667 - mae: 0.0667Epoch 80 completed. Loss: 0.0667, MAE: 0.0667, Val Loss: 0.0751, Val MAE: 0.0751\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0751 - val_mae: 0.0751\n",
      "Epoch 81/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0651 - mae: 0.0651Epoch 81 completed. Loss: 0.0653, MAE: 0.0653, Val Loss: 0.0697, Val MAE: 0.0697\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 82/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0668 - mae: 0.0668Epoch 82 completed. Loss: 0.0668, MAE: 0.0668, Val Loss: 0.0682, Val MAE: 0.0682\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 83/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0658 - mae: 0.0658Epoch 83 completed. Loss: 0.0658, MAE: 0.0658, Val Loss: 0.0636, Val MAE: 0.0636\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 84/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0664 - mae: 0.0664Epoch 84 completed. Loss: 0.0663, MAE: 0.0663, Val Loss: 0.1626, Val MAE: 0.1626\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.1626 - val_mae: 0.1626\n",
      "Epoch 85/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0645 - mae: 0.0645Epoch 85 completed. Loss: 0.0645, MAE: 0.0645, Val Loss: 0.0599, Val MAE: 0.0599\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0599 - val_mae: 0.0599\n",
      "Epoch 86/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0654 - mae: 0.0654Epoch 86 completed. Loss: 0.0652, MAE: 0.0652, Val Loss: 0.0703, Val MAE: 0.0703\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 87/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0640 - mae: 0.0640Epoch 87 completed. Loss: 0.0641, MAE: 0.0641, Val Loss: 0.0694, Val MAE: 0.0694\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 88/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0649 - mae: 0.0649Epoch 88 completed. Loss: 0.0647, MAE: 0.0647, Val Loss: 0.1335, Val MAE: 0.1335\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 89/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0641 - mae: 0.0641Epoch 89 completed. Loss: 0.0641, MAE: 0.0641, Val Loss: 0.0585, Val MAE: 0.0585\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 90/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0647 - mae: 0.0647Epoch 90 completed. Loss: 0.0647, MAE: 0.0647, Val Loss: 0.0712, Val MAE: 0.0712\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 91/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0657 - mae: 0.0657Epoch 91 completed. Loss: 0.0657, MAE: 0.0657, Val Loss: 0.0653, Val MAE: 0.0653\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 92/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0642 - mae: 0.0642Epoch 92 completed. Loss: 0.0637, MAE: 0.0637, Val Loss: 0.0652, Val MAE: 0.0652\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 93/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0635 - mae: 0.0635Epoch 93 completed. Loss: 0.0635, MAE: 0.0635, Val Loss: 0.0640, Val MAE: 0.0640\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 94/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0654 - mae: 0.0654Epoch 94 completed. Loss: 0.0652, MAE: 0.0652, Val Loss: 0.0631, Val MAE: 0.0631\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 95/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0637 - mae: 0.0637Epoch 95 completed. Loss: 0.0638, MAE: 0.0638, Val Loss: 0.0627, Val MAE: 0.0627\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 96/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0645 - mae: 0.0645Epoch 96 completed. Loss: 0.0645, MAE: 0.0645, Val Loss: 0.0650, Val MAE: 0.0650\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 97/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0639 - mae: 0.0639Epoch 97 completed. Loss: 0.0639, MAE: 0.0639, Val Loss: 0.0799, Val MAE: 0.0799\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0799 - val_mae: 0.0799\n",
      "Epoch 98/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0629 - mae: 0.0629Epoch 98 completed. Loss: 0.0628, MAE: 0.0628, Val Loss: 0.0684, Val MAE: 0.0684\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 99/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0632 - mae: 0.0632Epoch 99 completed. Loss: 0.0633, MAE: 0.0633, Val Loss: 0.0694, Val MAE: 0.0694\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 100/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0624 - mae: 0.0624Epoch 100 completed. Loss: 0.0625, MAE: 0.0625, Val Loss: 0.0669, Val MAE: 0.0669\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 101/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0627 - mae: 0.0627Epoch 101 completed. Loss: 0.0628, MAE: 0.0628, Val Loss: 0.0713, Val MAE: 0.0713\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 102/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0645 - mae: 0.0645Epoch 102 completed. Loss: 0.0645, MAE: 0.0645, Val Loss: 0.1170, Val MAE: 0.1170\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 103/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0620 - mae: 0.0620Epoch 103 completed. Loss: 0.0621, MAE: 0.0621, Val Loss: 0.0782, Val MAE: 0.0782\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0782 - val_mae: 0.0782\n",
      "Epoch 104/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0642 - mae: 0.0642Epoch 104 completed. Loss: 0.0643, MAE: 0.0643, Val Loss: 0.0689, Val MAE: 0.0689\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 105/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0630 - mae: 0.0630Epoch 105 completed. Loss: 0.0633, MAE: 0.0633, Val Loss: 0.0705, Val MAE: 0.0705\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 106/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0624 - mae: 0.0624Epoch 106 completed. Loss: 0.0624, MAE: 0.0624, Val Loss: 0.0589, Val MAE: 0.0589\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0624 - mae: 0.0624 - val_loss: 0.0589 - val_mae: 0.0589\n",
      "Epoch 107/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0626 - mae: 0.0626Epoch 107 completed. Loss: 0.0627, MAE: 0.0627, Val Loss: 0.0635, Val MAE: 0.0635\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0627 - mae: 0.0627 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 108/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0634 - mae: 0.0634Epoch 108 completed. Loss: 0.0633, MAE: 0.0633, Val Loss: 0.0613, Val MAE: 0.0613\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0613 - val_mae: 0.0613\n",
      "Epoch 109/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0621 - mae: 0.0621Epoch 109 completed. Loss: 0.0624, MAE: 0.0624, Val Loss: 0.0734, Val MAE: 0.0734\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0624 - mae: 0.0624 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 110/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0636 - mae: 0.0636Epoch 110 completed. Loss: 0.0635, MAE: 0.0635, Val Loss: 0.0911, Val MAE: 0.0911\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0911 - val_mae: 0.0911\n",
      "Epoch 111/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0614 - mae: 0.0614Epoch 111 completed. Loss: 0.0613, MAE: 0.0613, Val Loss: 0.0976, Val MAE: 0.0976\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0976 - val_mae: 0.0976\n",
      "Epoch 112/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0622 - mae: 0.0622Epoch 112 completed. Loss: 0.0622, MAE: 0.0622, Val Loss: 0.1052, Val MAE: 0.1052\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.1052 - val_mae: 0.1052\n",
      "Epoch 113/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0618 - mae: 0.0618Epoch 113 completed. Loss: 0.0617, MAE: 0.0617, Val Loss: 0.0679, Val MAE: 0.0679\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0617 - mae: 0.0617 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 114/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0626 - mae: 0.0626Epoch 114 completed. Loss: 0.0627, MAE: 0.0627, Val Loss: 0.0641, Val MAE: 0.0641\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0627 - mae: 0.0627 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 115/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0630 - mae: 0.0630Epoch 115 completed. Loss: 0.0629, MAE: 0.0629, Val Loss: 0.0639, Val MAE: 0.0639\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 116/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0608 - mae: 0.0608Epoch 116 completed. Loss: 0.0609, MAE: 0.0609, Val Loss: 0.0613, Val MAE: 0.0613\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.0613 - val_mae: 0.0613\n",
      "Epoch 117/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0606 - mae: 0.0606Epoch 117 completed. Loss: 0.0606, MAE: 0.0606, Val Loss: 0.0919, Val MAE: 0.0919\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0606 - mae: 0.0606 - val_loss: 0.0919 - val_mae: 0.0919\n",
      "Epoch 118/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0622 - mae: 0.0622Epoch 118 completed. Loss: 0.0622, MAE: 0.0622, Val Loss: 0.0642, Val MAE: 0.0642\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 119/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0614 - mae: 0.0614Epoch 119 completed. Loss: 0.0614, MAE: 0.0614, Val Loss: 0.0695, Val MAE: 0.0695\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 120/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0613 - mae: 0.0613Epoch 120 completed. Loss: 0.0613, MAE: 0.0613, Val Loss: 0.0652, Val MAE: 0.0652\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 121/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0610 - mae: 0.0610Epoch 121 completed. Loss: 0.0613, MAE: 0.0613, Val Loss: 0.0711, Val MAE: 0.0711\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0711 - val_mae: 0.0711\n",
      "Epoch 122/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0632 - mae: 0.0632Epoch 122 completed. Loss: 0.0633, MAE: 0.0633, Val Loss: 0.0595, Val MAE: 0.0595\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 123/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0654 - mae: 0.0654Epoch 123 completed. Loss: 0.0655, MAE: 0.0655, Val Loss: 0.0772, Val MAE: 0.0772\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0772 - val_mae: 0.0772\n",
      "Epoch 124/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0636 - mae: 0.0636Epoch 124 completed. Loss: 0.0635, MAE: 0.0635, Val Loss: 0.0617, Val MAE: 0.0617\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 125/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0627 - mae: 0.0627Epoch 125 completed. Loss: 0.0628, MAE: 0.0628, Val Loss: 0.0673, Val MAE: 0.0673\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 126/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0626 - mae: 0.0626Epoch 126 completed. Loss: 0.0626, MAE: 0.0626, Val Loss: 0.0686, Val MAE: 0.0686\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 127/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0629 - mae: 0.0629Epoch 127 completed. Loss: 0.0629, MAE: 0.0629, Val Loss: 0.0696, Val MAE: 0.0696\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 128/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0629 - mae: 0.0629Epoch 128 completed. Loss: 0.0628, MAE: 0.0628, Val Loss: 0.0789, Val MAE: 0.0789\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0789 - val_mae: 0.0789\n",
      "Epoch 129/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0623 - mae: 0.0623Epoch 129 completed. Loss: 0.0623, MAE: 0.0623, Val Loss: 0.0603, Val MAE: 0.0603\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0623 - mae: 0.0623 - val_loss: 0.0603 - val_mae: 0.0603\n",
      "Epoch 130/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0619 - mae: 0.0619Epoch 130 completed. Loss: 0.0618, MAE: 0.0618, Val Loss: 0.0669, Val MAE: 0.0669\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0618 - mae: 0.0618 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 131/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0622 - mae: 0.0622Epoch 131 completed. Loss: 0.0621, MAE: 0.0621, Val Loss: 0.0617, Val MAE: 0.0617\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 132/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0621 - mae: 0.0621Epoch 132 completed. Loss: 0.0625, MAE: 0.0625, Val Loss: 0.0829, Val MAE: 0.0829\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0829 - val_mae: 0.0829\n",
      "Epoch 133/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0636 - mae: 0.0636Epoch 133 completed. Loss: 0.0636, MAE: 0.0636, Val Loss: 0.0606, Val MAE: 0.0606\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 134/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0630 - mae: 0.0630Epoch 134 completed. Loss: 0.0631, MAE: 0.0631, Val Loss: 0.0763, Val MAE: 0.0763\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0763 - val_mae: 0.0763\n",
      "Epoch 135/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0615 - mae: 0.0615Epoch 135 completed. Loss: 0.0613, MAE: 0.0613, Val Loss: 0.0631, Val MAE: 0.0631\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 136/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0608 - mae: 0.0608Epoch 136 completed. Loss: 0.0609, MAE: 0.0609, Val Loss: 0.0630, Val MAE: 0.0630\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 137/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0610 - mae: 0.0610Epoch 137 completed. Loss: 0.0611, MAE: 0.0611, Val Loss: 0.0758, Val MAE: 0.0758\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0758 - val_mae: 0.0758\n",
      "Epoch 138/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0614 - mae: 0.0614Epoch 138 completed. Loss: 0.0613, MAE: 0.0613, Val Loss: 0.0657, Val MAE: 0.0657\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 139/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0607 - mae: 0.0607Epoch 139 completed. Loss: 0.0606, MAE: 0.0606, Val Loss: 0.0563, Val MAE: 0.0563\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0606 - mae: 0.0606 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 140/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0605 - mae: 0.0605Epoch 140 completed. Loss: 0.0606, MAE: 0.0606, Val Loss: 0.0658, Val MAE: 0.0658\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0606 - mae: 0.0606 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 141/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0606 - mae: 0.0606Epoch 141 completed. Loss: 0.0609, MAE: 0.0609, Val Loss: 0.0720, Val MAE: 0.0720\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.0720 - val_mae: 0.0720\n",
      "Epoch 142/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0600 - mae: 0.0600Epoch 142 completed. Loss: 0.0600, MAE: 0.0600, Val Loss: 0.0656, Val MAE: 0.0656\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 143/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0611 - mae: 0.0611Epoch 143 completed. Loss: 0.0611, MAE: 0.0611, Val Loss: 0.0628, Val MAE: 0.0628\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 144/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0609 - mae: 0.0609Epoch 144 completed. Loss: 0.0611, MAE: 0.0611, Val Loss: 0.0602, Val MAE: 0.0602\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0602 - val_mae: 0.0602\n",
      "Epoch 145/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0625 - mae: 0.0625Epoch 145 completed. Loss: 0.0625, MAE: 0.0625, Val Loss: 0.0636, Val MAE: 0.0636\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 146/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0606 - mae: 0.0606Epoch 146 completed. Loss: 0.0607, MAE: 0.0607, Val Loss: 0.0627, Val MAE: 0.0627\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 147/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0605 - mae: 0.0605Epoch 147 completed. Loss: 0.0608, MAE: 0.0608, Val Loss: 0.0644, Val MAE: 0.0644\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 148/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0603 - mae: 0.0603Epoch 148 completed. Loss: 0.0603, MAE: 0.0603, Val Loss: 0.0663, Val MAE: 0.0663\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 149/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0610 - mae: 0.0610Epoch 149 completed. Loss: 0.0610, MAE: 0.0610, Val Loss: 0.0934, Val MAE: 0.0934\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0610 - mae: 0.0610 - val_loss: 0.0934 - val_mae: 0.0934\n",
      "Epoch 150/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0603 - mae: 0.0603Epoch 150 completed. Loss: 0.0604, MAE: 0.0604, Val Loss: 0.0591, Val MAE: 0.0591\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 151/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0602 - mae: 0.0602Epoch 151 completed. Loss: 0.0602, MAE: 0.0602, Val Loss: 0.0626, Val MAE: 0.0626\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0602 - mae: 0.0602 - val_loss: 0.0626 - val_mae: 0.0626\n",
      "Epoch 152/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0617 - mae: 0.0617Epoch 152 completed. Loss: 0.0619, MAE: 0.0619, Val Loss: 0.0651, Val MAE: 0.0651\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0619 - mae: 0.0619 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 153/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0601 - mae: 0.0601Epoch 153 completed. Loss: 0.0601, MAE: 0.0601, Val Loss: 0.0654, Val MAE: 0.0654\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 154/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0606 - mae: 0.0606Epoch 154 completed. Loss: 0.0602, MAE: 0.0602, Val Loss: 0.0862, Val MAE: 0.0862\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0602 - mae: 0.0602 - val_loss: 0.0862 - val_mae: 0.0862\n",
      "Epoch 155/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0607 - mae: 0.0607Epoch 155 completed. Loss: 0.0605, MAE: 0.0605, Val Loss: 0.0897, Val MAE: 0.0897\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0605 - mae: 0.0605 - val_loss: 0.0897 - val_mae: 0.0897\n",
      "Epoch 156/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0616 - mae: 0.0616Epoch 156 completed. Loss: 0.0615, MAE: 0.0615, Val Loss: 0.0959, Val MAE: 0.0959\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0615 - mae: 0.0615 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 157/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0596 - mae: 0.0596Epoch 157 completed. Loss: 0.0597, MAE: 0.0597, Val Loss: 0.0653, Val MAE: 0.0653\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 158/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0618 - mae: 0.0618Epoch 158 completed. Loss: 0.0614, MAE: 0.0614, Val Loss: 0.0638, Val MAE: 0.0638\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 159/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0595 - mae: 0.0595Epoch 159 completed. Loss: 0.0598, MAE: 0.0598, Val Loss: 0.0686, Val MAE: 0.0686\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 160/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0604 - mae: 0.0604Epoch 160 completed. Loss: 0.0605, MAE: 0.0605, Val Loss: 0.0707, Val MAE: 0.0707\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0605 - mae: 0.0605 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 161/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0602 - mae: 0.0602Epoch 161 completed. Loss: 0.0602, MAE: 0.0602, Val Loss: 0.0606, Val MAE: 0.0606\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0602 - mae: 0.0602 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 162/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0584 - mae: 0.0584Epoch 162 completed. Loss: 0.0583, MAE: 0.0583, Val Loss: 0.0564, Val MAE: 0.0564\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0583 - mae: 0.0583 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 163/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0592 - mae: 0.0592Epoch 163 completed. Loss: 0.0592, MAE: 0.0592, Val Loss: 0.0734, Val MAE: 0.0734\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 164/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0602 - mae: 0.0602Epoch 164 completed. Loss: 0.0604, MAE: 0.0604, Val Loss: 0.0770, Val MAE: 0.0770\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0770 - val_mae: 0.0770\n",
      "Epoch 165/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0594 - mae: 0.0594Epoch 165 completed. Loss: 0.0593, MAE: 0.0593, Val Loss: 0.0583, Val MAE: 0.0583\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0593 - mae: 0.0593 - val_loss: 0.0583 - val_mae: 0.0583\n",
      "Epoch 166/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0601 - mae: 0.0601Epoch 166 completed. Loss: 0.0600, MAE: 0.0600, Val Loss: 0.0615, Val MAE: 0.0615\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 167/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0593 - mae: 0.0593Epoch 167 completed. Loss: 0.0594, MAE: 0.0594, Val Loss: 0.0937, Val MAE: 0.0937\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0594 - mae: 0.0594 - val_loss: 0.0937 - val_mae: 0.0937\n",
      "Epoch 168/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0593 - mae: 0.0593Epoch 168 completed. Loss: 0.0592, MAE: 0.0592, Val Loss: 0.0619, Val MAE: 0.0619\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0619 - val_mae: 0.0619\n",
      "Epoch 169/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0588 - mae: 0.0588Epoch 169 completed. Loss: 0.0587, MAE: 0.0587, Val Loss: 0.0617, Val MAE: 0.0617\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 170/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0596 - mae: 0.0596Epoch 170 completed. Loss: 0.0595, MAE: 0.0595, Val Loss: 0.0698, Val MAE: 0.0698\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0595 - mae: 0.0595 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 171/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0593 - mae: 0.0593Epoch 171 completed. Loss: 0.0591, MAE: 0.0591, Val Loss: 0.0705, Val MAE: 0.0705\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0591 - mae: 0.0591 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 172/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0586 - mae: 0.0586Epoch 172 completed. Loss: 0.0586, MAE: 0.0586, Val Loss: 0.0661, Val MAE: 0.0661\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 173/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0580 - mae: 0.0580Epoch 173 completed. Loss: 0.0581, MAE: 0.0581, Val Loss: 0.0627, Val MAE: 0.0627\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 174/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0586 - mae: 0.0586Epoch 174 completed. Loss: 0.0586, MAE: 0.0586, Val Loss: 0.0582, Val MAE: 0.0582\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 175/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0594 - mae: 0.0594Epoch 175 completed. Loss: 0.0594, MAE: 0.0594, Val Loss: 0.0598, Val MAE: 0.0598\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0594 - mae: 0.0594 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 176/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0593 - mae: 0.0593Epoch 176 completed. Loss: 0.0591, MAE: 0.0591, Val Loss: 0.0663, Val MAE: 0.0663\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0591 - mae: 0.0591 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 177/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0609 - mae: 0.0609Epoch 177 completed. Loss: 0.0607, MAE: 0.0607, Val Loss: 0.0840, Val MAE: 0.0840\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0840 - val_mae: 0.0840\n",
      "Epoch 178/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0587 - mae: 0.0587Epoch 178 completed. Loss: 0.0586, MAE: 0.0586, Val Loss: 0.0666, Val MAE: 0.0666\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 179/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0593 - mae: 0.0593Epoch 179 completed. Loss: 0.0593, MAE: 0.0593, Val Loss: 0.0593, Val MAE: 0.0593\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0593 - mae: 0.0593 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 180/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0588 - mae: 0.0588Epoch 180 completed. Loss: 0.0585, MAE: 0.0585, Val Loss: 0.0769, Val MAE: 0.0769\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0585 - mae: 0.0585 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 181/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0585 - mae: 0.0585Epoch 181 completed. Loss: 0.0585, MAE: 0.0585, Val Loss: 0.0643, Val MAE: 0.0643\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0585 - mae: 0.0585 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 182/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0584 - mae: 0.0584Epoch 182 completed. Loss: 0.0584, MAE: 0.0584, Val Loss: 0.0785, Val MAE: 0.0785\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0785 - val_mae: 0.0785\n",
      "Epoch 183/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0601 - mae: 0.0601Epoch 183 completed. Loss: 0.0601, MAE: 0.0601, Val Loss: 0.0774, Val MAE: 0.0774\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0774 - val_mae: 0.0774\n",
      "Epoch 184/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0593 - mae: 0.0593Epoch 184 completed. Loss: 0.0593, MAE: 0.0593, Val Loss: 0.0651, Val MAE: 0.0651\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0593 - mae: 0.0593 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 185/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0587 - mae: 0.0587Epoch 185 completed. Loss: 0.0585, MAE: 0.0585, Val Loss: 0.0707, Val MAE: 0.0707\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0585 - mae: 0.0585 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 186/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0583 - mae: 0.0583Epoch 186 completed. Loss: 0.0584, MAE: 0.0584, Val Loss: 0.0865, Val MAE: 0.0865\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0865 - val_mae: 0.0865\n",
      "Epoch 187/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0575 - mae: 0.0575Epoch 187 completed. Loss: 0.0577, MAE: 0.0577, Val Loss: 0.0927, Val MAE: 0.0927\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0927 - val_mae: 0.0927\n",
      "Epoch 188/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0584 - mae: 0.0584Epoch 188 completed. Loss: 0.0583, MAE: 0.0583, Val Loss: 0.0649, Val MAE: 0.0649\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0583 - mae: 0.0583 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 189/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0569 - mae: 0.0569Epoch 189 completed. Loss: 0.0568, MAE: 0.0568, Val Loss: 0.0662, Val MAE: 0.0662\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 190/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0576 - mae: 0.0576Epoch 190 completed. Loss: 0.0577, MAE: 0.0577, Val Loss: 0.0697, Val MAE: 0.0697\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 191/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0580 - mae: 0.0580Epoch 191 completed. Loss: 0.0579, MAE: 0.0579, Val Loss: 0.0634, Val MAE: 0.0634\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 192/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0574 - mae: 0.0574Epoch 192 completed. Loss: 0.0574, MAE: 0.0574, Val Loss: 0.0659, Val MAE: 0.0659\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 193/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0576 - mae: 0.0576Epoch 193 completed. Loss: 0.0577, MAE: 0.0577, Val Loss: 0.0657, Val MAE: 0.0657\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 194/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0566 - mae: 0.0566Epoch 194 completed. Loss: 0.0568, MAE: 0.0568, Val Loss: 0.0908, Val MAE: 0.0908\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0908 - val_mae: 0.0908\n",
      "Epoch 195/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0579 - mae: 0.0579Epoch 195 completed. Loss: 0.0579, MAE: 0.0579, Val Loss: 0.0591, Val MAE: 0.0591\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 196/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0581 - mae: 0.0581Epoch 196 completed. Loss: 0.0581, MAE: 0.0581, Val Loss: 0.0769, Val MAE: 0.0769\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 197/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0576 - mae: 0.0576Epoch 197 completed. Loss: 0.0575, MAE: 0.0575, Val Loss: 0.0574, Val MAE: 0.0574\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 198/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0564 - mae: 0.0564Epoch 198 completed. Loss: 0.0562, MAE: 0.0562, Val Loss: 0.0660, Val MAE: 0.0660\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 199/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0569 - mae: 0.0569Epoch 199 completed. Loss: 0.0569, MAE: 0.0569, Val Loss: 0.0589, Val MAE: 0.0589\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0589 - val_mae: 0.0589\n",
      "Epoch 200/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0569 - mae: 0.0569Epoch 200 completed. Loss: 0.0571, MAE: 0.0571, Val Loss: 0.0646, Val MAE: 0.0646\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 201/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0578 - mae: 0.0578Epoch 201 completed. Loss: 0.0579, MAE: 0.0579, Val Loss: 0.0643, Val MAE: 0.0643\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 202/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0571 - mae: 0.0571Epoch 202 completed. Loss: 0.0572, MAE: 0.0572, Val Loss: 0.0659, Val MAE: 0.0659\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 203/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0566 - mae: 0.0566Epoch 203 completed. Loss: 0.0569, MAE: 0.0569, Val Loss: 0.0638, Val MAE: 0.0638\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 204/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0574 - mae: 0.0574Epoch 204 completed. Loss: 0.0574, MAE: 0.0574, Val Loss: 0.0844, Val MAE: 0.0844\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0844 - val_mae: 0.0844\n",
      "Epoch 205/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0570 - mae: 0.0570Epoch 205 completed. Loss: 0.0570, MAE: 0.0570, Val Loss: 0.0868, Val MAE: 0.0868\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0868 - val_mae: 0.0868\n",
      "Epoch 206/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0561 - mae: 0.0561Epoch 206 completed. Loss: 0.0561, MAE: 0.0561, Val Loss: 0.0639, Val MAE: 0.0639\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 207/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0568 - mae: 0.0568Epoch 207 completed. Loss: 0.0568, MAE: 0.0568, Val Loss: 0.0942, Val MAE: 0.0942\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0942 - val_mae: 0.0942\n",
      "Epoch 208/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0564 - mae: 0.0564Epoch 208 completed. Loss: 0.0563, MAE: 0.0563, Val Loss: 0.0883, Val MAE: 0.0883\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0883 - val_mae: 0.0883\n",
      "Epoch 209/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0563 - mae: 0.0563Epoch 209 completed. Loss: 0.0562, MAE: 0.0562, Val Loss: 0.0615, Val MAE: 0.0615\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 210/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0565 - mae: 0.0565Epoch 210 completed. Loss: 0.0565, MAE: 0.0565, Val Loss: 0.0575, Val MAE: 0.0575\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0565 - mae: 0.0565 - val_loss: 0.0575 - val_mae: 0.0575\n",
      "Epoch 211/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0572 - mae: 0.0572Epoch 211 completed. Loss: 0.0574, MAE: 0.0574, Val Loss: 0.0620, Val MAE: 0.0620\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 212/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0561 - mae: 0.0561Epoch 212 completed. Loss: 0.0561, MAE: 0.0561, Val Loss: 0.0570, Val MAE: 0.0570\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 213/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0563 - mae: 0.0563Epoch 213 completed. Loss: 0.0559, MAE: 0.0559, Val Loss: 0.0597, Val MAE: 0.0597\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0597 - val_mae: 0.0597\n",
      "Epoch 214/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0572 - mae: 0.0572Epoch 214 completed. Loss: 0.0572, MAE: 0.0572, Val Loss: 0.0645, Val MAE: 0.0645\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 215/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0571 - mae: 0.0571Epoch 215 completed. Loss: 0.0570, MAE: 0.0570, Val Loss: 0.0719, Val MAE: 0.0719\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 216/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0560 - mae: 0.0560Epoch 216 completed. Loss: 0.0561, MAE: 0.0561, Val Loss: 0.0603, Val MAE: 0.0603\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0603 - val_mae: 0.0603\n",
      "Epoch 217/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0571 - mae: 0.0571Epoch 217 completed. Loss: 0.0570, MAE: 0.0570, Val Loss: 0.0599, Val MAE: 0.0599\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0599 - val_mae: 0.0599\n",
      "Epoch 218/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0553 - mae: 0.0553Epoch 218 completed. Loss: 0.0554, MAE: 0.0554, Val Loss: 0.0646, Val MAE: 0.0646\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 219/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0557 - mae: 0.0557Epoch 219 completed. Loss: 0.0557, MAE: 0.0557, Val Loss: 0.0587, Val MAE: 0.0587\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 220/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0556 - mae: 0.0556Epoch 220 completed. Loss: 0.0558, MAE: 0.0558, Val Loss: 0.1367, Val MAE: 0.1367\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.1367 - val_mae: 0.1367\n",
      "Epoch 221/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0548 - mae: 0.0548Epoch 221 completed. Loss: 0.0548, MAE: 0.0548, Val Loss: 0.0556, Val MAE: 0.0556\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0548 - mae: 0.0548 - val_loss: 0.0556 - val_mae: 0.0556\n",
      "Epoch 222/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0564 - mae: 0.0564Epoch 222 completed. Loss: 0.0561, MAE: 0.0561, Val Loss: 0.0817, Val MAE: 0.0817\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0817 - val_mae: 0.0817\n",
      "Epoch 223/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0558 - mae: 0.0558Epoch 223 completed. Loss: 0.0559, MAE: 0.0559, Val Loss: 0.0600, Val MAE: 0.0600\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 224/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0559 - mae: 0.0559Epoch 224 completed. Loss: 0.0559, MAE: 0.0559, Val Loss: 0.0648, Val MAE: 0.0648\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 225/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0550 - mae: 0.0550Epoch 225 completed. Loss: 0.0549, MAE: 0.0549, Val Loss: 0.0613, Val MAE: 0.0613\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0613 - val_mae: 0.0613\n",
      "Epoch 226/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0545 - mae: 0.0545Epoch 226 completed. Loss: 0.0545, MAE: 0.0545, Val Loss: 0.0564, Val MAE: 0.0564\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0545 - mae: 0.0545 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 227/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0546 - mae: 0.0546Epoch 227 completed. Loss: 0.0546, MAE: 0.0546, Val Loss: 0.0652, Val MAE: 0.0652\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0546 - mae: 0.0546 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 228/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0555 - mae: 0.0555Epoch 228 completed. Loss: 0.0556, MAE: 0.0556, Val Loss: 0.0578, Val MAE: 0.0578\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 229/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0553 - mae: 0.0553Epoch 229 completed. Loss: 0.0552, MAE: 0.0552, Val Loss: 0.0616, Val MAE: 0.0616\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0616 - val_mae: 0.0616\n",
      "Epoch 230/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0557 - mae: 0.0557Epoch 230 completed. Loss: 0.0559, MAE: 0.0559, Val Loss: 0.0900, Val MAE: 0.0900\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0900 - val_mae: 0.0900\n",
      "Epoch 231/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0551 - mae: 0.0551Epoch 231 completed. Loss: 0.0551, MAE: 0.0551, Val Loss: 0.0556, Val MAE: 0.0556\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0556 - val_mae: 0.0556\n",
      "Epoch 232/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0542 - mae: 0.0542Epoch 232 completed. Loss: 0.0541, MAE: 0.0541, Val Loss: 0.0725, Val MAE: 0.0725\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0541 - mae: 0.0541 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 233/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0551 - mae: 0.0551Epoch 233 completed. Loss: 0.0551, MAE: 0.0551, Val Loss: 0.0758, Val MAE: 0.0758\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0758 - val_mae: 0.0758\n",
      "Epoch 234/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0569 - mae: 0.0569Epoch 234 completed. Loss: 0.0568, MAE: 0.0568, Val Loss: 0.0582, Val MAE: 0.0582\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 235/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0551 - mae: 0.0551Epoch 235 completed. Loss: 0.0551, MAE: 0.0551, Val Loss: 0.1170, Val MAE: 0.1170\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 236/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0545 - mae: 0.0545Epoch 236 completed. Loss: 0.0544, MAE: 0.0544, Val Loss: 0.0574, Val MAE: 0.0574\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0544 - mae: 0.0544 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 237/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0542 - mae: 0.0542Epoch 237 completed. Loss: 0.0541, MAE: 0.0541, Val Loss: 0.0658, Val MAE: 0.0658\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0541 - mae: 0.0541 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 238/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0558 - mae: 0.0558Epoch 238 completed. Loss: 0.0559, MAE: 0.0559, Val Loss: 0.0591, Val MAE: 0.0591\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 239/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0562 - mae: 0.0562Epoch 239 completed. Loss: 0.0565, MAE: 0.0565, Val Loss: 0.0730, Val MAE: 0.0730\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0565 - mae: 0.0565 - val_loss: 0.0730 - val_mae: 0.0730\n",
      "Epoch 240/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0549 - mae: 0.0549Epoch 240 completed. Loss: 0.0549, MAE: 0.0549, Val Loss: 0.0570, Val MAE: 0.0570\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 241/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0553 - mae: 0.0553Epoch 241 completed. Loss: 0.0554, MAE: 0.0554, Val Loss: 0.0598, Val MAE: 0.0598\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 242/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0547 - mae: 0.0547Epoch 242 completed. Loss: 0.0549, MAE: 0.0549, Val Loss: 0.1420, Val MAE: 0.1420\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.1420 - val_mae: 0.1420\n",
      "Epoch 243/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0544 - mae: 0.0544Epoch 243 completed. Loss: 0.0544, MAE: 0.0544, Val Loss: 0.0623, Val MAE: 0.0623\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0544 - mae: 0.0544 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 244/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0549 - mae: 0.0549Epoch 244 completed. Loss: 0.0547, MAE: 0.0547, Val Loss: 0.0574, Val MAE: 0.0574\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0547 - mae: 0.0547 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 245/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0544 - mae: 0.0544Epoch 245 completed. Loss: 0.0545, MAE: 0.0545, Val Loss: 0.0666, Val MAE: 0.0666\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0545 - mae: 0.0545 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 246/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0548 - mae: 0.0548Epoch 246 completed. Loss: 0.0549, MAE: 0.0549, Val Loss: 0.0575, Val MAE: 0.0575\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0575 - val_mae: 0.0575\n",
      "Epoch 247/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0541 - mae: 0.0541Epoch 247 completed. Loss: 0.0540, MAE: 0.0540, Val Loss: 0.0620, Val MAE: 0.0620\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0540 - mae: 0.0540 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 248/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0549 - mae: 0.0549Epoch 248 completed. Loss: 0.0551, MAE: 0.0551, Val Loss: 0.0904, Val MAE: 0.0904\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0904 - val_mae: 0.0904\n",
      "Epoch 249/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0542 - mae: 0.0542Epoch 249 completed. Loss: 0.0542, MAE: 0.0542, Val Loss: 0.0797, Val MAE: 0.0797\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0542 - mae: 0.0542 - val_loss: 0.0797 - val_mae: 0.0797\n",
      "Epoch 250/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0533 - mae: 0.0533Epoch 250 completed. Loss: 0.0532, MAE: 0.0532, Val Loss: 0.0672, Val MAE: 0.0672\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0532 - mae: 0.0532 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 251/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0549 - mae: 0.0549Epoch 251 completed. Loss: 0.0550, MAE: 0.0550, Val Loss: 0.0705, Val MAE: 0.0705\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0550 - mae: 0.0550 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 252/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0542 - mae: 0.0542Epoch 252 completed. Loss: 0.0545, MAE: 0.0545, Val Loss: 0.0741, Val MAE: 0.0741\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0545 - mae: 0.0545 - val_loss: 0.0741 - val_mae: 0.0741\n",
      "Epoch 253/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0555 - mae: 0.0555Epoch 253 completed. Loss: 0.0555, MAE: 0.0555, Val Loss: 0.0707, Val MAE: 0.0707\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0555 - mae: 0.0555 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 254/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0533 - mae: 0.0533Epoch 254 completed. Loss: 0.0534, MAE: 0.0534, Val Loss: 0.0709, Val MAE: 0.0709\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0534 - mae: 0.0534 - val_loss: 0.0709 - val_mae: 0.0709\n",
      "Epoch 255/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0542 - mae: 0.0542Epoch 255 completed. Loss: 0.0542, MAE: 0.0542, Val Loss: 0.0603, Val MAE: 0.0603\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0542 - mae: 0.0542 - val_loss: 0.0603 - val_mae: 0.0603\n",
      "Epoch 256/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0537 - mae: 0.0537Epoch 256 completed. Loss: 0.0537, MAE: 0.0537, Val Loss: 0.0593, Val MAE: 0.0593\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0537 - mae: 0.0537 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 257/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0543 - mae: 0.0543Epoch 257 completed. Loss: 0.0543, MAE: 0.0543, Val Loss: 0.0736, Val MAE: 0.0736\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0543 - mae: 0.0543 - val_loss: 0.0736 - val_mae: 0.0736\n",
      "Epoch 258/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0545 - mae: 0.0545Epoch 258 completed. Loss: 0.0545, MAE: 0.0545, Val Loss: 0.0630, Val MAE: 0.0630\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0545 - mae: 0.0545 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 259/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0533 - mae: 0.0533Epoch 259 completed. Loss: 0.0532, MAE: 0.0532, Val Loss: 0.0619, Val MAE: 0.0619\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0532 - mae: 0.0532 - val_loss: 0.0619 - val_mae: 0.0619\n",
      "Epoch 260/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0526 - mae: 0.0526Epoch 260 completed. Loss: 0.0528, MAE: 0.0528, Val Loss: 0.0545, Val MAE: 0.0545\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0528 - mae: 0.0528 - val_loss: 0.0545 - val_mae: 0.0545\n",
      "Epoch 261/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0536 - mae: 0.0536Epoch 261 completed. Loss: 0.0535, MAE: 0.0535, Val Loss: 0.0587, Val MAE: 0.0587\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0535 - mae: 0.0535 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 262/300\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.0526 - mae: 0.0526Epoch 262 completed. Loss: 0.0526, MAE: 0.0526, Val Loss: 0.0626, Val MAE: 0.0626\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0626 - val_mae: 0.0626\n",
      "Epoch 263/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0547 - mae: 0.0547Epoch 263 completed. Loss: 0.0548, MAE: 0.0548, Val Loss: 0.0601, Val MAE: 0.0601\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0548 - mae: 0.0548 - val_loss: 0.0601 - val_mae: 0.0601\n",
      "Epoch 264/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0553 - mae: 0.0553Epoch 264 completed. Loss: 0.0552, MAE: 0.0552, Val Loss: 0.0620, Val MAE: 0.0620\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 265/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0542 - mae: 0.0542Epoch 265 completed. Loss: 0.0543, MAE: 0.0543, Val Loss: 0.0700, Val MAE: 0.0700\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0543 - mae: 0.0543 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 266/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0539 - mae: 0.0539Epoch 266 completed. Loss: 0.0541, MAE: 0.0541, Val Loss: 0.0764, Val MAE: 0.0764\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0541 - mae: 0.0541 - val_loss: 0.0764 - val_mae: 0.0764\n",
      "Epoch 267/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0534 - mae: 0.0534Epoch 267 completed. Loss: 0.0534, MAE: 0.0534, Val Loss: 0.0602, Val MAE: 0.0602\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0534 - mae: 0.0534 - val_loss: 0.0602 - val_mae: 0.0602\n",
      "Epoch 268/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0530 - mae: 0.0530Epoch 268 completed. Loss: 0.0530, MAE: 0.0530, Val Loss: 0.0630, Val MAE: 0.0630\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 269/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0535 - mae: 0.0535Epoch 269 completed. Loss: 0.0533, MAE: 0.0533, Val Loss: 0.0668, Val MAE: 0.0668\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0533 - mae: 0.0533 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 270/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0530 - mae: 0.0530Epoch 270 completed. Loss: 0.0530, MAE: 0.0530, Val Loss: 0.0550, Val MAE: 0.0550\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 271/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0540 - mae: 0.0540Epoch 271 completed. Loss: 0.0539, MAE: 0.0539, Val Loss: 0.0616, Val MAE: 0.0616\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0539 - mae: 0.0539 - val_loss: 0.0616 - val_mae: 0.0616\n",
      "Epoch 272/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0526 - mae: 0.0526Epoch 272 completed. Loss: 0.0526, MAE: 0.0526, Val Loss: 0.0549, Val MAE: 0.0549\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0549 - val_mae: 0.0549\n",
      "Epoch 273/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0526 - mae: 0.0526Epoch 273 completed. Loss: 0.0526, MAE: 0.0526, Val Loss: 0.0572, Val MAE: 0.0572\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0572 - val_mae: 0.0572\n",
      "Epoch 274/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0532 - mae: 0.0532Epoch 274 completed. Loss: 0.0532, MAE: 0.0532, Val Loss: 0.0765, Val MAE: 0.0765\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0532 - mae: 0.0532 - val_loss: 0.0765 - val_mae: 0.0765\n",
      "Epoch 275/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0528 - mae: 0.0528Epoch 275 completed. Loss: 0.0527, MAE: 0.0527, Val Loss: 0.0584, Val MAE: 0.0584\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0527 - mae: 0.0527 - val_loss: 0.0584 - val_mae: 0.0584\n",
      "Epoch 276/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0537 - mae: 0.0537Epoch 276 completed. Loss: 0.0536, MAE: 0.0536, Val Loss: 0.0532, Val MAE: 0.0532\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0536 - mae: 0.0536 - val_loss: 0.0532 - val_mae: 0.0532\n",
      "Epoch 277/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0528 - mae: 0.0528Epoch 277 completed. Loss: 0.0528, MAE: 0.0528, Val Loss: 0.0638, Val MAE: 0.0638\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0528 - mae: 0.0528 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 278/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0530 - mae: 0.0530Epoch 278 completed. Loss: 0.0530, MAE: 0.0530, Val Loss: 0.0906, Val MAE: 0.0906\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0906 - val_mae: 0.0906\n",
      "Epoch 279/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0531 - mae: 0.0531Epoch 279 completed. Loss: 0.0530, MAE: 0.0530, Val Loss: 0.0765, Val MAE: 0.0765\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0765 - val_mae: 0.0765\n",
      "Epoch 280/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0525 - mae: 0.0525Epoch 280 completed. Loss: 0.0524, MAE: 0.0524, Val Loss: 0.0737, Val MAE: 0.0737\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0737 - val_mae: 0.0737\n",
      "Epoch 281/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0535 - mae: 0.0535Epoch 281 completed. Loss: 0.0536, MAE: 0.0536, Val Loss: 0.0701, Val MAE: 0.0701\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0536 - mae: 0.0536 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 282/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0525 - mae: 0.0525Epoch 282 completed. Loss: 0.0525, MAE: 0.0525, Val Loss: 0.0568, Val MAE: 0.0568\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0525 - mae: 0.0525 - val_loss: 0.0568 - val_mae: 0.0568\n",
      "Epoch 283/300\n",
      "276/279 [============================>.] - ETA: 0s - loss: 0.0526 - mae: 0.0526Epoch 283 completed. Loss: 0.0527, MAE: 0.0527, Val Loss: 0.1073, Val MAE: 0.1073\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0527 - mae: 0.0527 - val_loss: 0.1073 - val_mae: 0.1073\n",
      "Epoch 284/300\n",
      "268/279 [===========================>..] - ETA: 0s - loss: 0.0529 - mae: 0.0529Epoch 284 completed. Loss: 0.0527, MAE: 0.0527, Val Loss: 0.0644, Val MAE: 0.0644\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0527 - mae: 0.0527 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 285/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0528 - mae: 0.0528Epoch 285 completed. Loss: 0.0528, MAE: 0.0528, Val Loss: 0.0688, Val MAE: 0.0688\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0528 - mae: 0.0528 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 286/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0515 - mae: 0.0515Epoch 286 completed. Loss: 0.0514, MAE: 0.0514, Val Loss: 0.0571, Val MAE: 0.0571\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0514 - mae: 0.0514 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 287/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0522 - mae: 0.0522Epoch 287 completed. Loss: 0.0524, MAE: 0.0524, Val Loss: 0.0622, Val MAE: 0.0622\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 288/300\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.0522 - mae: 0.0522Epoch 288 completed. Loss: 0.0522, MAE: 0.0522, Val Loss: 0.0558, Val MAE: 0.0558\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0522 - mae: 0.0522 - val_loss: 0.0558 - val_mae: 0.0558\n",
      "Epoch 289/300\n",
      "273/279 [============================>.] - ETA: 0s - loss: 0.0523 - mae: 0.0523Epoch 289 completed. Loss: 0.0526, MAE: 0.0526, Val Loss: 0.0845, Val MAE: 0.0845\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0845 - val_mae: 0.0845\n",
      "Epoch 290/300\n",
      "266/279 [===========================>..] - ETA: 0s - loss: 0.0524 - mae: 0.0524Epoch 290 completed. Loss: 0.0524, MAE: 0.0524, Val Loss: 0.0810, Val MAE: 0.0810\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0810 - val_mae: 0.0810\n",
      "Epoch 291/300\n",
      "271/279 [============================>.] - ETA: 0s - loss: 0.0521 - mae: 0.0521Epoch 291 completed. Loss: 0.0520, MAE: 0.0520, Val Loss: 0.0733, Val MAE: 0.0733\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0520 - mae: 0.0520 - val_loss: 0.0733 - val_mae: 0.0733\n",
      "Epoch 292/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0524 - mae: 0.0524Epoch 292 completed. Loss: 0.0524, MAE: 0.0524, Val Loss: 0.0767, Val MAE: 0.0767\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0767 - val_mae: 0.0767\n",
      "Epoch 293/300\n",
      "270/279 [============================>.] - ETA: 0s - loss: 0.0524 - mae: 0.0524Epoch 293 completed. Loss: 0.0528, MAE: 0.0528, Val Loss: 0.0580, Val MAE: 0.0580\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0528 - mae: 0.0528 - val_loss: 0.0580 - val_mae: 0.0580\n",
      "Epoch 294/300\n",
      "278/279 [============================>.] - ETA: 0s - loss: 0.0522 - mae: 0.0522Epoch 294 completed. Loss: 0.0523, MAE: 0.0523, Val Loss: 0.0557, Val MAE: 0.0557\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0557 - val_mae: 0.0557\n",
      "Epoch 295/300\n",
      "277/279 [============================>.] - ETA: 0s - loss: 0.0527 - mae: 0.0527Epoch 295 completed. Loss: 0.0526, MAE: 0.0526, Val Loss: 0.0592, Val MAE: 0.0592\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0592 - val_mae: 0.0592\n",
      "Epoch 296/300\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.0523 - mae: 0.0523Epoch 296 completed. Loss: 0.0523, MAE: 0.0523, Val Loss: 0.0761, Val MAE: 0.0761\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0761 - val_mae: 0.0761\n",
      "Epoch 297/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0517 - mae: 0.0517Epoch 297 completed. Loss: 0.0518, MAE: 0.0518, Val Loss: 0.1410, Val MAE: 0.1410\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0518 - mae: 0.0518 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 298/300\n",
      "267/279 [===========================>..] - ETA: 0s - loss: 0.0527 - mae: 0.0527Epoch 298 completed. Loss: 0.0529, MAE: 0.0529, Val Loss: 0.0617, Val MAE: 0.0617\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0529 - mae: 0.0529 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 299/300\n",
      "275/279 [============================>.] - ETA: 0s - loss: 0.0532 - mae: 0.0532Epoch 299 completed. Loss: 0.0532, MAE: 0.0532, Val Loss: 0.0728, Val MAE: 0.0728\n",
      "279/279 [==============================] - 1s 5ms/step - loss: 0.0532 - mae: 0.0532 - val_loss: 0.0728 - val_mae: 0.0728\n",
      "Epoch 300/300\n",
      "274/279 [============================>.] - ETA: 0s - loss: 0.0529 - mae: 0.0529Epoch 300 completed. Loss: 0.0533, MAE: 0.0533, Val Loss: 0.1036, Val MAE: 0.1036\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.0533 - mae: 0.0533 - val_loss: 0.1036 - val_mae: 0.1036\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1036 - mae: 0.1036\n",
      "Validation MAE: 0.10361789166927338\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "Submission file saved to C:/Users/mavsi/Documents/NN/Trabalho/Dados\\submission1.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define model\n",
    "def build_model1(input_shape):\n",
    "    \n",
    "    model1 = Sequential([\n",
    "        # First convolutional layer with 64 filters, kernel size of 3x3, padding 'same', and ReLU activation - extract features from the images\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(), # Stabilize Model Training\n",
    "        MaxPooling2D((2, 2)), # Downsampling the image to reduce the number of parameters and computation in the network and hence to control overfitting\n",
    "        Dropout(0.3), # Prevent overfitting\n",
    "        \n",
    "        # Second convolutional layer with 128 filters, kernel size of 3x3, padding 'same', and ReLU activation\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(), # Stabilize Model Training\n",
    "        MaxPooling2D((2, 2)), # Downsampling the image to reduce the number of parameters and computation in the network and hence to control overfitting\n",
    "        Dropout(0.3), # Prevent overfitting\n",
    "        \n",
    "        # Third convolutional layer with 256 filters, kernel size of 3x3, padding 'same', and ReLU activation\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(), # Stabilize Model Training\n",
    "        MaxPooling2D((2, 2)), # Downsampling the image to reduce the number of parameters and computation in the network and hence to control overfitting\n",
    "        Dropout(0.3), # Prevent overfitting\n",
    "\n",
    "        # Flatten layer to convert 2D data to 1D\n",
    "        Flatten(),\n",
    "\n",
    "        # Fully connected dense layer with 512 units and ReLU activation\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3), #Prevent overfitting \n",
    "\n",
    "        # Fully connected dense layer with 256 units and ReLU activation\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3), #Prevent overfitting\n",
    "\n",
    "        # Fully connected dense layer with 128 units and ReLU activation\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3), #Prevent overfitting\n",
    "\n",
    "        # Output layer with 1 unit (for regression) default linear activation\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Compile the model with the Adam optimizer\n",
    "    model1.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
    "    \n",
    "    '''Adam calculates a moving average of the first-order moments (the mean of gradients) \n",
    "    and the second-order moments (the uncentered variance of gradients) to scale the learning rates adaptively. \n",
    "    This makes it well-suited for problems with sparse gradients or noisy data.'''\n",
    "    \n",
    "    #R eturns model\n",
    "    return model1\n",
    "\n",
    "# Build the model\n",
    "model1 = build_model1(x_train_images.shape[1:])\n",
    "# Prints model summary info\n",
    "model1.summary()\n",
    "\n",
    "# Train-validation split: 80-20 ratio\n",
    "x_train_split1, x_val_split1, y_train_split1, y_val_split1 = train_test_split(x_train_images, y_train, test_size=0.2, random_state=20)\n",
    "\n",
    "# Define a custom callback for printing training progress after each epoch to track the model's performance during training\n",
    "class trainingprogress(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        print(f\"Epoch {epoch+1} completed. Loss: {logs['loss']:.4f}, MAE: {logs['mae']:.4f}, Val Loss: {logs['val_loss']:.4f}, Val MAE: {logs['val_mae']:.4f}\")\n",
    "\n",
    "# Train the model with the custom callback\n",
    "history1 = model1.fit(x_train_split1, y_train_split1, epochs=300, batch_size=30, validation_data=(x_val_split1, y_val_split1), callbacks=[trainingprogress()]) \n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history1.history['mae'], label='Train MAE')\n",
    "plt.plot(history1.history['val_mae'], label='Val MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Model Evaluation\n",
    "val_loss1, val_mae1 = model1.evaluate(x_val_split1, y_val_split1) # Evaluate the model on the validation data\n",
    "print(f'Validation MAE: {val_mae1}') # Print the validation MAE\n",
    "\n",
    "# Making Predictions and Preparing Submission\n",
    "predictions = model1.predict(x_test_images)\n",
    "\n",
    "# Prepare submission file\n",
    "output_dir1 = 'Resultados'  # Specify the directory where to save the submission file\n",
    "submission1 = pd.DataFrame({'id': test_df['id'], 'AOT_550': predictions.flatten()}) # Create a DataFrame with the ID and predictions\n",
    "submission_file_path1 = os.path.join(output_dir1, 'submission1.csv') # Specify the path to save the submission file\n",
    "submission1.to_csv(submission_file_path1, index=False) # Save the DataFrame to a CSV file without row numbers\n",
    "\n",
    "print(f'Submission file saved to {submission_file_path1}') # Print the path to the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103af378-6483-4cf8-8bb3-3e6fc3c9cf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 19, 19, 64)        7552      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 9, 9, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 9, 9, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,067,521\n",
      "Trainable params: 1,066,625\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 3/84 [>.............................] - ETA: 5s - loss: 2.1790 - mae: 2.1790WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.0175s). Check your callbacks.\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4166 - mae: 0.4166 - val_loss: 0.1247 - val_mae: 0.1247\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.0936 - val_mae: 0.0936\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0966 - mae: 0.0966 - val_loss: 0.0904 - val_mae: 0.0904\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.0863 - mae: 0.0863 - val_loss: 0.0951 - val_mae: 0.0951\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.0822 - mae: 0.0822 - val_loss: 0.0797 - val_mae: 0.0797\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0788 - mae: 0.0788 - val_loss: 0.0914 - val_mae: 0.0914\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0773 - mae: 0.0773 - val_loss: 0.1569 - val_mae: 0.1569\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0773 - mae: 0.0773 - val_loss: 0.0949 - val_mae: 0.0949\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0761 - mae: 0.0761 - val_loss: 0.0838 - val_mae: 0.0838\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0744 - mae: 0.0744 - val_loss: 0.0863 - val_mae: 0.0863\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0757 - mae: 0.0757 - val_loss: 0.0862 - val_mae: 0.0862\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0746 - mae: 0.0746 - val_loss: 0.0783 - val_mae: 0.0783\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0736 - mae: 0.0736 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0726 - mae: 0.0726 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0731 - mae: 0.0731 - val_loss: 0.0777 - val_mae: 0.0777\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.2745 - val_mae: 0.2745\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0727 - mae: 0.0727 - val_loss: 0.0907 - val_mae: 0.0907\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0717 - mae: 0.0717 - val_loss: 0.0885 - val_mae: 0.0885\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0709 - mae: 0.0709 - val_loss: 0.0975 - val_mae: 0.0975\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0708 - mae: 0.0708 - val_loss: 0.3053 - val_mae: 0.3053\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.1090 - val_mae: 0.1090\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0837 - val_mae: 0.0837\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.1061 - val_mae: 0.1061\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0691 - mae: 0.0691 - val_loss: 0.0828 - val_mae: 0.0828\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0772 - val_mae: 0.0772\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0954 - val_mae: 0.0954\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.4715 - val_mae: 0.4715\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0833 - val_mae: 0.0833\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0971 - val_mae: 0.0971\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.1071 - val_mae: 0.1071\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0747 - val_mae: 0.0747\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0765 - val_mae: 0.0765\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0805 - val_mae: 0.0805\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0783 - val_mae: 0.0783\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0821 - val_mae: 0.0821\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0855 - val_mae: 0.0855\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0752 - val_mae: 0.0752\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.1774 - val_mae: 0.1774\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.1490 - val_mae: 0.1490\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.1017 - val_mae: 0.1017\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0858 - val_mae: 0.0858\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0794 - val_mae: 0.0794\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.1432 - val_mae: 0.1432\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0813 - val_mae: 0.0813\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0863 - val_mae: 0.0863\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0749 - val_mae: 0.0749\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0949 - val_mae: 0.0949\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0748 - val_mae: 0.0748\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0921 - val_mae: 0.0921\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0751 - val_mae: 0.0751\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0627 - mae: 0.0627 - val_loss: 0.0782 - val_mae: 0.0782\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.0634 - mae: 0.0634 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.1003 - val_mae: 0.1003\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0616 - mae: 0.0616 - val_loss: 0.0743 - val_mae: 0.0743\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0627 - mae: 0.0627 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0619 - mae: 0.0619 - val_loss: 0.0776 - val_mae: 0.0776\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0617 - mae: 0.0617 - val_loss: 0.0744 - val_mae: 0.0744\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0616 - mae: 0.0616 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0726 - val_mae: 0.0726\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0910 - val_mae: 0.0910\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.1813 - val_mae: 0.1813\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0620 - mae: 0.0620 - val_loss: 0.0815 - val_mae: 0.0815\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0746 - val_mae: 0.0746\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0589 - mae: 0.0589 - val_loss: 0.1187 - val_mae: 0.1187\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.1019 - val_mae: 0.1019\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0739 - val_mae: 0.0739\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0772 - val_mae: 0.0772\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0591 - mae: 0.0591 - val_loss: 0.1132 - val_mae: 0.1132\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0580 - mae: 0.0580 - val_loss: 0.0911 - val_mae: 0.0911\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0588 - mae: 0.0588 - val_loss: 0.0609 - val_mae: 0.0609\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0823 - val_mae: 0.0823\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0588 - mae: 0.0588 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0732 - val_mae: 0.0732\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0576 - mae: 0.0576 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0585 - mae: 0.0585 - val_loss: 0.0576 - val_mae: 0.0576\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0767 - val_mae: 0.0767\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0831 - val_mae: 0.0831\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0730 - val_mae: 0.0730\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.0576 - mae: 0.0576 - val_loss: 0.0839 - val_mae: 0.0839\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0840 - mae: 0.0840\n",
      "Validation MAE: 0.0839511975646019\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "Submission file saved to C:/Users/mavsi/Documents/NN/Trabalho/Dados\\submission2.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define model\n",
    "def build_model2(input_shape):\n",
    "    \n",
    "    model2 = Sequential([\n",
    "        # First convolutional layer with 64 filters, kernel size of 3x3, padding 'same', and ReLU activation - extract features from the images\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(), # Stabilize Model Training\n",
    "        MaxPooling2D((2, 2)), # Downsampling the image to reduce the number of parameters and computation in the network and hence to control overfitting\n",
    "        Dropout(0.3), # Prevent overfitting\n",
    "        \n",
    "        # Second convolutional layer with 128 filters, kernel size of 3x3, padding 'same', and ReLU activation\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(), # Stabilize Model Training\n",
    "        MaxPooling2D((2, 2)), # Downsampling the image to reduce the number of parameters and computation in the network and hence to control overfitting\n",
    "        Dropout(0.3), # Prevent overfitting\n",
    "        \n",
    "        # Third convolutional layer with 256 filters, kernel size of 3x3, padding 'same', and ReLU activation\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(), # Stabilize Model Training\n",
    "        MaxPooling2D((2, 2)), # Downsampling the image to reduce the number of parameters and computation in the network and hence to control overfitting\n",
    "        Dropout(0.3), # Prevent overfitting\n",
    "\n",
    "        # Flatten layer to convert 2D data to 1D\n",
    "        Flatten(),\n",
    "\n",
    "        # Fully connected dense layer with 512 units and ReLU activation\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3), #Prevent overfitting \n",
    "\n",
    "        # Fully connected dense layer with 256 units and ReLU activation\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3), #Prevent overfitting\n",
    "\n",
    "        # Fully connected dense layer with 128 units and ReLU activation\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3), #Prevent overfitting\n",
    "\n",
    "        # Output layer with 1 unit (for regression) default linear activation\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Compile the model with the Adam optimizer\n",
    "    model2.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
    "    \n",
    "    '''Adam calculates a moving average of the first-order moments (the mean of gradients) \n",
    "    and the second-order moments (the uncentered variance of gradients) to scale the learning rates adaptively. \n",
    "    This makes it well-suited for problems with sparse gradients or noisy data.'''\n",
    "    \n",
    "    #R eturns model\n",
    "    return model2\n",
    "\n",
    "# Build the model\n",
    "model2 = build_model2(x_train_images.shape[1:])\n",
    "# Prints model summary info\n",
    "model2.summary()\n",
    "\n",
    "# Train-validation split: 80-20 ratio\n",
    "x_train_split2, x_val_split2, y_train_split2, y_val_split2 = train_test_split(x_train_images, y_train, test_size=0.2, random_state=20)\n",
    "\n",
    "# Define a custom callback for printing training progress after each epoch to track the model's performance during training\n",
    "class trainingprogress(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end2(self, epoch, logs=None): \n",
    "        print(f\"Epoch {epoch+1} completed. Loss: {logs['loss']:.4f}, MAE: {logs['mae']:.4f}, Val Loss: {logs['val_loss']:.4f}, Val MAE: {logs['val_mae']:.4f}\")\n",
    "\n",
    "# Train the model with the custom callback\n",
    "history2 = model2.fit(x_train_split2, y_train_split2, epochs=100, batch_size=100, validation_data=(x_val_split2, y_val_split2), callbacks=[trainingprogress()]) \n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history2.history['mae'], label='Train MAE')\n",
    "plt.plot(history2.history['val_mae'], label='Val MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Model Evaluation\n",
    "val_loss2, val_mae2 = model2.evaluate(x_val_split2, y_val_split2) # Evaluate the model on the validation data\n",
    "print(f'Validation MAE: {val_mae2}') # Print the validation MAE\n",
    "\n",
    "# Making Predictions and Preparing Submission\n",
    "predictions2 = model2.predict(x_test_images)\n",
    "\n",
    "# Prepare submission file\n",
    "output_dir2 = 'Resultados'  # Specify the directory where to save the submission file\n",
    "submission2 = pd.DataFrame({'id': test_df['id'], 'AOT_550': predictions2.flatten()}) # Create a DataFrame with the ID and predictions\n",
    "submission_file_path2 = os.path.join(output_dir2, 'submission2.csv') # Specify the path to save the submission file\n",
    "submission2.to_csv(submission_file_path2, index=False) # Save the DataFrame to a CSV file without row numbers\n",
    "\n",
    "print(f'Submission file saved to {submission_file_path2}') # Print the path to the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fd85d-fb77-4e52-b75d-34531a67770a",
   "metadata": {},
   "source": [
    "## Discussion on the Models Outputs\n",
    "\n",
    "The objective was to build and submit models capable of estimating the Aerosol Optical Thickness (AOT) at 550 nm for a specific location using Sentinel-2 images. Here we compare and discuss the results of two different model configurations:\n",
    "\n",
    "### Model 1 - Submission 1\n",
    "\n",
    "**Validation MAE obtained:** 0.0560 (the values may differ because the models code had to be run again)\n",
    "\n",
    "#### Observations:\n",
    "\n",
    "**Training Curve:**  \n",
    "The first training curve indicates a decrease in Mean Absolute Error (MAE) over 300 epochs. This suggests that the model effectively learns and improves its predictions over a more extended training period.\n",
    "\n",
    "**Validation Curve:**  \n",
    "The validation MAE exhibits fluctuations but shows a general trend of decreasing. This variability could indicate some overfitting as the model might be capturing noise in the training data over such a long training duration.\n",
    "\n",
    "### Model 2 - Submission 2\n",
    "\n",
    "**Validation MAE obtained:** 0.0676 (the values may differ because the models code had to be run again)\n",
    "#### Observations:\n",
    "\n",
    "**Training Curve:**  \n",
    "The training MAE decreases steadily suggesting that the model is learning effectively.\n",
    "\n",
    "**Validation Curve:**  \n",
    "The validation MAE shows more significant fluctuations than the first submission. The larger batch size of 100 might be causing the model to converge faster but it might also be missing out on finer details that smaller batches could capture.\n",
    "\n",
    "## Results Discussion\n",
    "\n",
    "When comparing the two different submissions, we noticed some differences in how they performed and were trained. The first submission achieved a MAE of 0.0560, which means it had better accuracy on new unseen data compared to the second submission which had a validation MAE of 0.0676. This suggests that the first model was generally more effective in making predictions on the test dataset data.\n",
    "\n",
    "The first model underwent a longer training process of 300 epochs and it used smaller batches of 30 at a time. This slower, more detailed approach likely allowed the model to capture more subtle patterns in the data, leading to its better performance in validation. In contrast, the second model was trained for only 100 epochs and used larger batches of 100. While this sped up the training process, it may have caused the model to miss some of the details in the dataset. This could explain why its validation MAE was slightly higher.\n",
    "\n",
    "Another observation was how unstable each model's validation MAE values were during training. The first model showed some higher fluctuations in its validation MAE over time which could suggest it was occasionally overfitting the data. However, despite these fluctuations, it consistently performed better overall. The second model, even with a higher batch size, also a lot of fluctuations on the MAE validation, indicating it might not have had enough time to fully stabilize its learning process.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In conclusion, the choice of epochs and batch size significantly impacts the model's performance. While the first model trained for more epochs and with a smaller batch size yielded better results, it also showed signs of overfitting. The second model, with fewer epochs and a larger batch size, was trained faster but had a slightly higher validation MAE.\n",
    "\n",
    "Unfortunately, since we didn’t start this project with the needed time and even though we only made two submissions, we surpassed a lot of obstacles during this project, since the configuration of python with “tensorflow” that required an older python version and “miniconda” to utilize the GPU to make the calculations, to the data preprocessing phase that during the majority of the time was giving us test MAE values in the best of cases of 3 and we didn’t find that the problem was the way we were extracting the AOT values until a couple of hours before the submission timeline. This last setback was the cause of us only making two submissions and we didn’t submit the other architectures tested for our design and even other model parameters and experimental iterations that could be relevant to discuss, learn and obtain a deeper understanding of the whole process of building a model.\n",
    "\n",
    "Even with this partially successful experimentation and exploration of a model building process, the whole project served as a good teaching tool for us as our first model building process from start to finish and helped to acquire a better understanding of the impact of different training configurations and guides adjustments to improve future models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d95069-e020-40c1-b962-5dc90abb8ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
